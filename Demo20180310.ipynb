{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3\n",
    "b = 2\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 英文斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'book']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'this is a book'\n",
    "s.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規表達法斷句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = '''\n",
    "被視為美食聖經的《米其林指南》，在3月7日發布台北版「必比登推介」（Bib Gourmand）美食，共36家平價美食店家入選，包括：臭豆腐、藥燉排骨、麻油雞等道地的夜市小吃，也有8家國民美食牛肉麵入選，鼎泰豐、點水樓等名店也沒缺席。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n被視為美食聖經的《米其林指南》',\n",
       " '在3月7日發布台北版',\n",
       " '必比登推介',\n",
       " '（Bib Gourmand）美食',\n",
       " '共36家平價美食店家入選',\n",
       " '包括',\n",
       " '臭豆腐',\n",
       " '藥燉排骨',\n",
       " '麻油雞等道地的夜市小吃',\n",
       " '也有8家國民美食牛肉麵入選',\n",
       " '鼎泰豐',\n",
       " '點水樓等名店也沒缺席。\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split('，|：|、|「|」',news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝 Jieba\n",
    "- pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in c:\\programdata\\anaconda3\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "! pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "s = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "seg = jieba.cut(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Tokenizer.cut at 0x00000000050220A0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.299 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['大', '巨蛋', '案對', '市府', '同仁', '下', '封口令', '？', '\\u3000', '柯', 'P', '否認']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大/巨蛋/案對/市府/同仁/下/封口令/？/\\u3000/柯/P/否認'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "s = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "seg = jieba.cut(s)\n",
    "'/'.join(seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 處理英文資料 (NLTK)\n",
    "- pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'on',\n",
       " 'Thursday',\n",
       " 'morning',\n",
       " 'Arthur',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'feel',\n",
       " 'very',\n",
       " 'good']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "sentence = \"At eight o'clock on Thursday morning Arthur didn't feel very good\"\n",
    "tags = nltk.word_tokenize(sentence)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('At', 'IN'),\n",
       " ('eight', 'CD'),\n",
       " (\"o'clock\", 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Thursday', 'NNP'),\n",
       " ('morning', 'NN'),\n",
       " ('Arthur', 'NNP'),\n",
       " ('did', 'VBD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('feel', 'VB'),\n",
       " ('very', 'RB'),\n",
       " ('good', 'JJ')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tags)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphic\n",
      "imag\n",
      "imag\n",
      "imagin\n",
      "imagin\n"
     ]
    }
   ],
   "source": [
    "import nltk.stem\n",
    "s= nltk.stem.SnowballStemmer('english')\n",
    "print(s.stem(\"graphics\"))\n",
    "\n",
    "print(s.stem(\"imaging\"))\n",
    "print(s.stem(\"image\"))\n",
    "print(s.stem(\"imagination\"))\n",
    "print(s.stem(\"imagine\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "sw = stopwords.words('english')\n",
    "#sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Jieba 斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['大', '巨蛋', '案', '對', '市府', '同仁', '下', '封口', '封口令', '口令', '', '', '', '柯', 'P', '否', '認']\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "s = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "# 全模式\n",
    "seg = jieba.cut(s, cut_all=True)\n",
    "print(list(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['大', '巨蛋', '案對', '市府', '同仁', '下', '封口令', '？', '\\u3000', '柯', 'P', '否認']\n"
     ]
    }
   ],
   "source": [
    "# 精準模式\n",
    "seg = jieba.cut(s)\n",
    "print(list(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['大巨蛋', '案對', '市府', '同仁', '下', '封口令', '？', '\\u3000', '柯P', '否認']\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict('userdict.txt')\n",
    "seg = jieba.cut(s)\n",
    "print(list(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pair('大巨蛋', 'n'),\n",
       " pair('案', 'ng'),\n",
       " pair('對', 'p'),\n",
       " pair('市府', 'n'),\n",
       " pair('同仁', 'nr'),\n",
       " pair('下', 'f'),\n",
       " pair('封口令', 'n'),\n",
       " pair('？', 'x'),\n",
       " pair('\\u3000', 'x'),\n",
       " pair('柯P', 'n'),\n",
       " pair('否認', 'v')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋 0 3\n",
      "案對 3 5\n",
      "市府 5 7\n",
      "同仁 7 9\n",
      "下 9 10\n",
      "封口令 10 13\n",
      "？ 13 14\n",
      "　 14 15\n",
      "柯P 15 17\n",
      "否認 17 19\n"
     ]
    }
   ],
   "source": [
    "words = jieba.tokenize(s)\n",
    "\n",
    "for tw in words:\n",
    "    print(tw[0], tw[1], tw[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用網路爬蟲抓取自由時報關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "res = requests.get('http://news.ltn.com.tw/news/politics/breakingnews/2360857')\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "with open('userdict.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write('\\n')\n",
    "    for rec in soup.select('.keyword a'):\n",
    "        f.write(rec.text+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切n-gram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'那我'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '那我們酸民婉君也可以報名嗎?'\n",
    "s[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我們'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'嗎?'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[len(s) - 2: len(s) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那我\n",
      "我們\n",
      "們酸\n",
      "酸民\n",
      "民婉\n",
      "婉君\n",
      "君也\n",
      "也可\n",
      "可以\n",
      "以報\n",
      "報名\n",
      "名嗎\n",
      "嗎?\n"
     ]
    }
   ],
   "source": [
    "# bi-gram: 2-gram\n",
    "for i in range(0, len(s) - 2 + 1):\n",
    "    print(s[i:i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那我們\n",
      "我們酸\n",
      "們酸民\n",
      "酸民婉\n",
      "民婉君\n",
      "婉君也\n",
      "君也可\n",
      "也可以\n",
      "可以報\n",
      "以報名\n",
      "報名嗎\n",
      "名嗎?\n"
     ]
    }
   ],
   "source": [
    "# tri-gram: 3-trim\n",
    "for i in range(0, len(s) - 3 + 1):\n",
    "    print(s[i:i+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ngram(input_sentence, n = 2):\n",
    "    ret = []\n",
    "    for i in range(0, len(input_sentence) - n + 1):\n",
    "        ret.append(input_sentence[i:i+n])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'那我們酸民婉君也可以報名嗎?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['那我', '我們', '們酸', '酸民', '民婉', '婉君', '君也', '也可', '可以', '以報', '報名', '名嗎', '嗎?']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(s, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['那我們',\n",
       " '我們酸',\n",
       " '們酸民',\n",
       " '酸民婉',\n",
       " '民婉君',\n",
       " '婉君也',\n",
       " '君也可',\n",
       " '也可以',\n",
       " '可以報',\n",
       " '以報名',\n",
       " '報名嗎',\n",
       " '名嗎?']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(s, n= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = '''\n",
    "〔即時新聞／綜合報導〕新制《勞基法》已於本月開始上路，但時代力量、社民黨及勞工、學生團體認為勞基法修惡，現已著手整合不同版本的《勞基法》複決公投提案，欲在年底「公投綁大選」翻案。據悉，已由「勞權公投聯盟」的版本出線！\n",
    "\n",
    " 5月1日勞動節大遊行時，勞基法複決公投預計也會被列為今年活動主軸之一。（資料照，記者陳鈺馥攝）\n",
    "5月1日勞動節大遊行時，勞基法複決公投預計也會被列為今年活動主軸之一。（資料照，記者陳鈺馥攝）\n",
    "\n",
    "綜合媒體報導，時代力量、社民黨、醫勞盟日前曾開會討論此事，時代力量立委徐永明指出，時代力量不堅持自己的提案版本，而希望透過相互整合及各自努力，加速完成下階段的連署。\n",
    "\n",
    "公投連署成案須至少28萬份連署書的最低門檻，預計3月底展開連署，勞權公投聯盟（簡稱勞公聯）則訂出「希望獨立完成30萬份連署」目標。徐永明認為這會是第三勢力新的合作模式：議題彼此相互整合，共同擴大支持範圍。支持範圍愈大，相信也會反映在年底的選舉結果。\n",
    "\n",
    "醫勞盟理事長儲寧瑋表示，醫勞盟的立場是希望極力促成11/24廢止過勞勞基法的公投，因此不會堅持自己的提案。兩個團體也都允諾會全力衝刺第二階段連署書收集。\n",
    "\n",
    "勞工部分預計4、5月將「組織動員」，由各地工會、勞工團體爭取基層勞工支持連署，5月1日勞動節大遊行時，勞基法複決公投預計也會被列為今年活動主軸之一。\n",
    "\n",
    "反教育商品化聯盟成員謝毅弘表示，5、6月間將到各校宣傳及擺攤蒐集連署書，7月放暑假後，則會組團到全台環島串連，趕在8月底前累積30萬份連署書。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = ngram(news,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用字典方式做統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for w in words:\n",
    "    if w not in dic:\n",
    "        dic[w] = 1\n",
    "    else:\n",
    "        dic[w] = dic[w] + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('連署', 9),\n",
       " ('勞基', 7),\n",
       " ('基法', 7),\n",
       " ('\\n\\n', 6),\n",
       " ('預計', 5),\n",
       " ('。\\n', 5),\n",
       " ('時代', 4),\n",
       " ('代力', 4),\n",
       " ('力量', 4)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "swd = sorted(dic.items(), key = operator.itemgetter(1), reverse=True)\n",
    "swd[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = ngram(news,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for w in words:\n",
    "    if w not in dic:\n",
    "        dic[w] = 1\n",
    "    else:\n",
    "        dic[w] = dic[w] + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('時代力', 4),\n",
       " ('代力量', 4),\n",
       " ('複決公', 4),\n",
       " ('決公投', 4),\n",
       " ('。\\n\\n', 4),\n",
       " ('連署書', 4),\n",
       " ('5月1', 3),\n",
       " ('月1日', 3),\n",
       " ('1日勞', 3)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "swd = sorted(dic.items(), key = operator.itemgetter(1), reverse=True)\n",
    "swd[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 2: 3, 3: 1}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,2,2,1]\n",
    "dic2 = {}\n",
    "for l in a:\n",
    "    if l not in dic2:\n",
    "        dic2[l] = 1\n",
    "    else:\n",
    "        dic2[l] = dic2[l] + 1\n",
    "dic2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Counter 統計詞頻\n",
    "- https://docs.python.org/3.6/library/collections.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2, 2: 3, 3: 1})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "a = [1,2,3,2,2,1]\n",
    "c = Counter(a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 3), (1, 2), (3, 1)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('勞基法', 7), ('時代力', 4), ('代力量', 4), ('複決公', 4), ('決公投', 4)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ngram(news,3)\n",
    "c = Counter(words)\n",
    "c.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('時代力量', 4), ('複決公投', 4), ('5月1日', 3), ('月1日勞', 3), ('1日勞動', 3)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ngram(news,4)\n",
    "c = Counter(words)\n",
    "c.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('公投', 9), ('連署', 9), ('勞基', 7), ('基法', 7), ('\\n\\n', 6)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ngram(news,2)\n",
    "c = Counter(words)\n",
    "c.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 長詞優先法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "sentenceAry = re.split('，|。|（|）|〕|〔|／|《|》|、|」|！|「|：',news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sentenceAry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'期貨 美核准上市'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '比特幣期貨 美核准上市'\n",
    "a.replace('比特幣', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 美上市'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeKey(text, keywords):\n",
    "    ret = text\n",
    "    for word in keywords:\n",
    "        ret = ret.replace(word, '')\n",
    "    return ret\n",
    "\n",
    "removeKey(a, ['比特幣', '核准', '期貨'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, [2, 3, 4]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [2,3,4]\n",
    "a.append(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 2, 3, 4]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [2,3,4]\n",
    "a.extend(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['時代力量', '複決公投', '勞基法', '連署書', '勞工', '公投', '\\n\\n', '5月', '預計', '也會', '連署']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = []\n",
    "\n",
    "for n in range(4,1,-1):\n",
    "    #print(n)\n",
    "    words = []\n",
    "    for sentence in sentenceAry:\n",
    "        text_list = removeKey(sentence, keywords)\n",
    "        words.extend(ngram(text_list, n))\n",
    "    c = Counter(words)\n",
    "    for word, cnt in c.items():\n",
    "        if cnt >= 4:\n",
    "            keywords.append(word)\n",
    "keywords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立一長詞優先處理函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = '''\n",
    "位於大直區的教父牛排，日前已證實收到米其林邀請函出席3/14(三)媒體發佈會與晚宴，台北君品酒店以粵菜為主打的頤宮中餐廳也同樣證實已在邀請行列。消息一出，台北君品酒店的行銷公關副理王懿萱則低調表示，頤宮目前正值後場整修調整中，預定3/13起可重新開放，接受顧客訂位，3/14並會與主廚前往米其林指南的媒體發佈會。\n",
    " \n",
    "在台灣牛排界赫赫有名的鄧有癸，曾打造國賓A CUT牛排館與維多利雅NO168 PRIME等知名頂級牛排館，一向以引領食尚風潮著稱，連教父牛排Danny’s Steakhouse在2013開幕當時，店內引進的美國木香烤爐更是全台唯一。已於3/2即獲得邀函的鄧有癸也謙稱，無論封星與否，一切功勞都要感謝旗下工作同仁與得力主廚吳曉芳。\n",
    " \n",
    "採炭火直烤的方式十分考驗主廚功力外，鄧師傅的得力左右手吳曉芳行政總主廚也為大直店嚴格把關，極受歡迎的頂級老饕牛排、菲力老饕牛排或溫煮龍蝦、每日鮮魚等都是店內極受歡迎的主要菜式。\n",
    " \n",
    "鄧有癸說：「上蓋肉乃選自美國肋眼的精華部位，每7公斤才能取下約1公斤的份量，其肉質不但頗具嚼勁，更有細緻的油花與飽滿風味。」即便每客老饕牛排3080元(6oz)要價不斐，但店內仍有不少熟客定期報到，更常見情侶約會選在此處品味頂級牛排風味。(林沛縈／台北報導)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def longTermFirst(news, keywords, threshold):\n",
    "    sentenceAry = re.split('，|。|（|）|〕|〔|／|《|》|、|」|！|「|：',news)\n",
    "\n",
    "    for n in range(4,1,-1):\n",
    "        words = []\n",
    "        for sentence in sentenceAry:\n",
    "            text_list = removeKey(sentence, keywords)\n",
    "            words.extend(ngram(text_list, n))\n",
    "            \n",
    "        c = Counter(words)\n",
    "        for word, cnt in c.items():\n",
    "            m = re.match('^[\\u4e00-\\u9fa5]+$', word)\n",
    "            if (cnt >= threshold) and m:\n",
    "                keywords.append(word)\n",
    "    return keywords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['老饕牛排', '鄧有癸', '牛排', '台北', '主廚', '頂級', '店內']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longTermFirst(news, [],3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用正規表達法篩選中文字詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "老饕牛排\n",
      "鄧有癸\n",
      "牛排\n",
      "台北\n",
      "主廚\n",
      "頂級\n",
      "店內\n"
     ]
    }
   ],
   "source": [
    "words = ['老饕牛排', '3/1', '\\n \\n', '鄧有癸', '牛排', '台北', '主廚', '頂級', '店內']\n",
    "\n",
    "import re\n",
    "for w in words:\n",
    "    m = re.match('^[\\u4e00-\\u9fa5]+$', w)\n",
    "    if m:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 詞頻統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article = '''\n",
    "一、積極促進在投資和經濟合作領域加快給予台資企業與大陸企業同等待遇\n",
    "1. 台灣同胞在大陸投資的企業 (以下簡稱「台資企業」) 參與「中國製造 2025」行動計劃適用與大陸企業同等政策。支持台商來大陸投資設立高端製造、智能製造、綠色製造等企業並設立區域總部和研發設計中心，相應享受稅收、投資等相關支持政策。\n",
    "\n",
    "2. 幫助和支持符合條件的台資企業依法享受高新技術企業減按 15% 稅率徵收企業所得稅，研發費用加計扣除，設在大陸的研發中心採購大陸設備全額退還增值稅等稅收優惠政策。\n",
    "\n",
    "3. 台灣科研機構、高等學校、企業在大陸註冊的獨立法人，可牽頭或參與國家重點研發計劃項目申報，享受與大陸科研機構、高等學校、企業同等政策。受聘於在大陸註冊的獨立法人的台灣地區科研人員，可作為國家重點研發計劃項目 (課題) 負責人申報，享受與大陸科研人員同等政策。對台灣地區知識產權在大陸轉化的，可參照執行大陸知識產權激勵政策。\n",
    "\n",
    "4. 台資企業可以特許經營方式參與能源、交通、水利、環保、市政公用工程等基礎設施建設。\n",
    "\n",
    "5. 台資企業可公平參與政府採購。\n",
    "\n",
    "6. 台資企業可通過合資合作、併購重組等方式參與國有企業混合所有製改革。\n",
    "\n",
    "7. 台資企業與大陸企業同等適用相關用地政策。對集約用地的鼓勵類台商投資工業項目優先供應土地，在確定土地出讓底價時，可按不低於所在地土地等別相對應大陸工業用地出讓最低價標準的 70% 執行。\n",
    "\n",
    "8. 繼續在中西部、東北地區設立海峽兩岸產業合作區，鼓勵台資企業向中西部、東北地區轉移並參與「一帶一路」建設，拓展內需市場和國際市場。大力推進台商投資區和兩岸環保產業合作示範基地建設。\n",
    "\n",
    "9. 台資農業企業可與大陸農業企業同等享受農機購置補貼、產業化重點龍頭企業等農業支持政策和優惠措施。\n",
    "\n",
    "10. 台灣金融機構、商家可與中國銀聯及大陸非銀行支付機構依法合規開展合作，為台灣同胞提供便捷的小額支付服務。\n",
    "\n",
    "11. 台灣徵信機構可與大陸徵信機構開展合作，為兩岸同胞和企業提供徵信服務。\n",
    "\n",
    "12. 台資銀行可與大陸同業協作，通過銀團貸款等方式為實體經濟提供金融服務。\n",
    "\n",
    "二、逐步為台灣同胞在大陸學習、創業、就業、生活提供與大陸同胞同等的待遇\n",
    "13. 台灣同胞可報名參加 53 項專業技術人員職業資格考試和 81 項技能人員職業資格考試 (《向台灣居民開放的國家職業資格考試目錄》附後，具體執業辦法由有關部門另行製定)。\n",
    "\n",
    "14. 台灣專業人才可申請參與國家「千人計劃」。在大陸工作的台灣專業人才，可申請參與國家「萬人計劃」。\n",
    "\n",
    "15. 台灣同胞可申報國家自然科學基金、國家社會科學基金、國家傑出青年科學基金、國家藝術基金等各類基金項目。具體辦法由相關主管部門製定。\n",
    "\n",
    "16. 鼓勵台灣同胞參與中華經典誦讀工程、文化遺產保護工程、非物質文化遺產傳承發展工程等中華優秀傳統文化傳承發展工程。支持台灣文化藝術界團體和人士參與大陸在海外舉辦的感知中國、中國文化年 (節)、歡樂春節等品牌活動，參加「中華文化走出去」計劃。符合條件的兩岸文化項目可納入海外中國文化中心項目資源庫。\n",
    "\n",
    "17. 支持中華慈善獎、梅花獎、金鷹獎等經濟科技文化社會領域各類評獎項目提名涵蓋台灣地區。在大陸工作的台灣同胞可參加當地勞動模範、「五一」勞動獎章、技術能手、「三八」紅旗手等榮譽稱號評選。\n",
    "\n",
    "18. 台灣人士參與大陸廣播電視節目和電影、電視劇製作可不受數量限制。\n",
    "\n",
    "19. 大陸電影發行機構、廣播電視台、視聽網站和有線電視網引進台灣生產的電影、電視劇不做數量限制。\n",
    "\n",
    "20. 放寬兩岸合拍電影、電視劇在主創人員比例、大陸元素、投資比例等方面的限制；取消收取兩岸電影合拍立項申報費用；縮短兩岸電視劇合拍立項階段故事梗概的審批時限。\n",
    "\n",
    "21. 對台灣圖書進口業務建立綠色通道，簡化進口審批流程。同時段進口的台灣圖書可優先辦理相關手續。\n",
    "\n",
    "22. 鼓勵台灣同胞加入大陸經濟、科技、文化、藝術類專業性社團組織、行業協會，參加相關活動。\n",
    "\n",
    "23. 支持鼓勵兩岸教育文化科研機構開展中國文化、歷史、民族等領域研究和成果應用。\n",
    "\n",
    "24. 台灣地區從事兩岸民間交流的機構可申請兩岸交流基金項目。\n",
    "\n",
    "25. 鼓勵台灣同胞和相關社團參與大陸扶貧、支教、公益、社區建設等基層工作。\n",
    "\n",
    "26. 在大陸高校就讀臨床醫學專業碩士學位的台灣學生，在參加研究生學習一年後，可按照大陸醫師資格考試報名的相關規定申請參加考試。\n",
    "\n",
    "27. 取得大陸醫師資格證書的台灣同胞，可按照相關規定在大陸申請執業註冊。\n",
    "\n",
    "28. 符合條件的台灣醫師，可通過認定方式獲得大陸醫師資格。符合條件的台灣醫師，可按照相關規定在大陸申請註冊短期行醫，期滿後可重新辦理註冊手續。\n",
    "\n",
    "29. 在台灣已獲取相應資格的台灣同胞在大陸申請證券、期貨、基金從業資格時，只需通過大陸法律法規考試，無需參加專業知識考試。\n",
    "\n",
    "30. 鼓勵台灣教師來大陸高校任教，其在台灣取得的學術成果可納入工作評價體系。\n",
    "\n",
    "31. 為方便台灣同胞在大陸應聘工作，推動各類人事人才網站和企業線上招聘做好系統升級，支持使用台胞證註冊登錄。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords = longTermFirst(article, ['大陸', '臺灣'], 5)\n",
    "\n",
    "with open('userdict.txt', 'a', encoding='utf-8') as f:\n",
    "    for w in keywords:\n",
    "        f.write(w+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大陸\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# unpacking\n",
    "k, v = ('大陸', 38)\n",
    "print(k)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大陸 38\n",
      "台灣 15\n",
      "台灣同胞 12\n",
      "參與 12\n",
      "文化 12\n",
      "企業 10\n",
      "兩岸 10\n",
      "相關 9\n",
      "機構 9\n",
      "國家 9\n",
      "台資企業 8\n",
      "政策 8\n",
      "支持 8\n",
      "項目 8\n",
      "資格 8\n",
      "投資 7\n",
      "鼓勵 7\n",
      "參加 7\n",
      "考試 7\n",
      "申請 7\n",
      "基金 7\n",
      "電視 7\n",
      "合作 6\n",
      "中國 6\n",
      "計劃 6\n",
      "註冊 6\n",
      "的台灣 6\n",
      "地區 6\n",
      "專業 6\n",
      "企業同等 5\n",
      "研發 5\n",
      "享受 5\n",
      "科研 5\n",
      "人員 5\n",
      "工程 5\n",
      "工作 5\n",
      "電影 5\n",
      "醫師 5\n",
      "經濟 4\n",
      "符合 4\n",
      "條件 4\n",
      "申報 4\n",
      "方式 4\n",
      "建設 4\n",
      "提供 4\n",
      "領域 3\n",
      "台商 3\n",
      "中心 3\n",
      "技術 3\n",
      "重點 3\n",
      "用地 3\n",
      "土地 3\n",
      "農業 3\n",
      "開展 3\n",
      "職業 3\n",
      "人才 3\n",
      "各類 3\n",
      "中華 3\n",
      "限制 3\n",
      "合拍 3\n",
      "按照 3\n",
      "規定 3\n",
      "待遇 2\n",
      "適用 2\n",
      "設立 2\n",
      "相應 2\n",
      "稅收 2\n",
      "依法 2\n",
      "費用 2\n",
      "採購 2\n",
      "優惠 2\n",
      "高等 2\n",
      "學校 2\n",
      "立法 2\n",
      "同等 2\n",
      "知識產權 2\n",
      "執行 2\n",
      "工業 2\n",
      "中西部 2\n",
      "東北 2\n",
      "台資 2\n",
      "金融 2\n",
      "支付 2\n",
      "服務 2\n",
      "徵信 2\n",
      "同胞 2\n",
      "學習 2\n",
      "具體 2\n",
      "執業 2\n",
      "辦法 2\n",
      "社會 2\n",
      "發展 2\n",
      "人士 2\n",
      "海外 2\n",
      "活動 2\n",
      "可納入 2\n",
      "科技 2\n",
      "勞動 2\n",
      "廣播 2\n",
      "網站 2\n",
      "比例 2\n",
      "立項 2\n",
      "審批 2\n",
      "圖書 2\n",
      "進口 2\n",
      "辦理 2\n",
      "手續 2\n",
      "成果 2\n",
      "交流 2\n",
      "高校 2\n",
      "取得 2\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from collections import Counter\n",
    "\n",
    "jieba.load_userdict('userdict.txt')\n",
    "c = Counter(list(jieba.cut(article)))\n",
    "for k,v in c.most_common():\n",
    "    if (len(k) >= 2) and (v >= 2):\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "a, abb ,abc = ['a'], ['a', 'b', 'b'], ['a', 'b', 'c']\n",
    "D = [a,abb,abc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('a', a, D)\n",
    "tf  = 1/1\n",
    "idf = sp.log(3/3)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('a', abb, D)\n",
    "tf  = 1/3\n",
    "idf = sp.log(3/3)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('a', abc, D)\n",
    "tf  = 1/3\n",
    "idf = sp.log(3/3)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27031007207210955"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('b', abb, D)\n",
    "tf  = 2/3\n",
    "idf = sp.log(3/2)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13515503603605478"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('b', abc, D)\n",
    "tf  = 1/3\n",
    "idf = sp.log(3/2)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36620409622270322"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('c', abc, D)\n",
    "tf  = 1/3\n",
    "idf = sp.log(3/1)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count\n",
    "a= [1,2,3,1,1,2]\n",
    "a.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf(t,d,D):\n",
    "    tf  = d.count(t) / len(d)\n",
    "    idf = sp.log(len(D) / len([doc for doc in D if t in doc]) )\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('a', a, D)\n",
    "tfidf('a', abb, D)\n",
    "tfidf('a', abc, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27031007207210955"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('b', abb, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13515503603605478"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('b', abc, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36620409622270322"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('c', abc, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['那酸民婉君']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "tags = jieba.analyse.extract_tags('那酸民婉君也可以報名嗎', 1)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?jieba.analyse.set_idf_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 詞頻矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1@2@3'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## string join\n",
    "s = ['1', '2', '3']\n",
    "' '.join(s)\n",
    "'@'.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'car', 'is', 'my', 'this']\n",
      "[[1 0 1 0 1]\n",
      " [0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "corpus = ['this is a book', 'this is my car']\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ary = ['【更新】柯P：洪智坤洩漏公文案還沒看到公文　今處理',\n",
    "       '留洪智坤 柯：殘障求職不易',\n",
    "       '人事處議處洪智坤　柯P：不清楚議處結果']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "for title in ary:\n",
    "    corpus.append(' '.join(jieba.cut(title)) )\n",
    "#jieba.cut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['【 更新 】 柯P ： 洪智坤 洩漏 公文 案還 沒 看到 公文 \\u3000 今處理',\n",
       " '留 洪智坤   柯 ： 殘障 求職 不易',\n",
       " '人事處 議處 洪智坤 \\u3000 柯P ： 不 清楚 議處 結果']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不易', '人事處', '今處理', '公文', '更新', '柯p', '案還', '殘障', '求職', '洩漏', '洪智坤', '清楚', '看到', '結果', '議處']\n",
      "[[0 0 1 2 1 1 1 0 0 1 1 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 1 1 0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ary = ['【更新】柯P：洪智坤洩漏公文案還沒看到公文　今處理',\n",
    "       '留洪智坤 柯文哲：殘障求職不易',\n",
    "       '人事處議處洪智坤　柯P：不清楚議處結果']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "for title in ary:\n",
    "    corpus.append(' '.join(jieba.cut(title)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不易', '人事處', '今處理', '公文', '更新', '柯p', '柯文哲', '案還', '殘障', '求職', '洩漏', '洪智坤', '清楚', '看到', '結果', '議處']\n",
      "[[0 0 1 2 1 1 0 1 0 0 1 1 0 1 0 0]\n",
      " [1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入同義詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['台灣/臺灣/Taiwan', '川普/特郎普', '柯文哲/柯p/柯P']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym = [w.strip() for w in  open('synonym.txt', 'r')]\n",
    "synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Taiwan': '台灣',\n",
       " '台灣': '台灣',\n",
       " '川普': '川普',\n",
       " '柯P': '柯文哲',\n",
       " '柯p': '柯文哲',\n",
       " '柯文哲': '柯文哲',\n",
       " '特郎普': '川普',\n",
       " '臺灣': '台灣'}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_dic = {}\n",
    "for term in synonym:\n",
    "    words = term.split('/')\n",
    "    for w in words:\n",
    "        synonym_dic[w] = words[0]\n",
    "synonym_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ary = ['【更新】柯P：洪智坤洩漏公文案還沒看到公文　今處理',\n",
    "       '留洪智坤 柯文哲：殘障求職不易',\n",
    "       '人事處議處洪智坤　柯P：不清楚議處結果']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['人事處', '議處', '洪智坤', '\\u3000', '柯文哲', '：', '不', '清楚', '議處', '結果']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '人事處議處洪智坤　柯P：不清楚議處結果'\n",
    "[synonym_dic.get(w, w) for w in jieba.cut(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不易', '人事處', '今處理', '公文', '更新', '柯文哲', '案還', '殘障', '求職', '洩漏', '洪智坤', '清楚', '看到', '結果', '議處']\n",
      "[[0 0 1 2 1 1 1 0 0 1 1 0 1 0 0]\n",
      " [1 0 0 0 0 1 0 1 1 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 1 1 0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "for title in ary:\n",
    "    #corpus.append(' '.join(jieba.cut(title)) )\n",
    "    corpus.append(' '.join(\\\n",
    "        [synonym_dic.get(w, w) for w in jieba.cut(title)]) )\n",
    "    \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 留下白名單字詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whilelist = ['市府', '柯文哲', '洪智坤']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['柯文哲', '洪智坤']\n",
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "for title in ary:\n",
    "    #corpus.append(' '.join(jieba.cut(title)) )\n",
    "    corpus.append(' '.join(\\\n",
    "        [synonym_dic.get(w, w) for w in jieba.cut(title) \\\n",
    "         if synonym_dic.get(w, w) in whilelist]) )\n",
    "    \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 排除停用詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不易', '人事處', '今處理', '公文', '柯文哲', '案還', '殘障', '求職', '洩漏', '洪智坤', '清楚', '結果', '議處']\n",
      "[[0 0 1 2 1 1 0 0 1 1 0 0 0]\n",
      " [1 0 0 0 1 0 1 1 0 1 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 0 1 1 1 2]]\n"
     ]
    }
   ],
   "source": [
    "stopwords = ['更新', '看到']\n",
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "for title in ary:\n",
    "    #corpus.append(' '.join(jieba.cut(title)) )\n",
    "    corpus.append(' '.join(\\\n",
    "        [synonym_dic.get(w, w) for w in jieba.cut(title) \\\n",
    "         if synonym_dic.get(w, w) not in stopwords]) )\n",
    "    \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算出TF-IDF 矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不易', '人事處', '今處理', '公文', '柯文哲', '案還', '殘障', '求職', '洩漏', '洪智坤', '清楚', '結果', '議處']\n",
      "[[ 0.          0.          0.36042988  0.72085976  0.21287569  0.36042988\n",
      "   0.          0.          0.36042988  0.21287569  0.          0.          0.        ]\n",
      " [ 0.52004008  0.          0.          0.          0.30714405  0.\n",
      "   0.52004008  0.52004008  0.          0.30714405  0.          0.          0.        ]\n",
      " [ 0.          0.36042988  0.          0.          0.21287569  0.          0.\n",
      "   0.          0.          0.21287569  0.36042988  0.36042988  0.72085976]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算文章相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ary = ['【更新】柯P：洪智坤洩漏公文案還沒看到公文　今處理',\n",
    "       '留洪智坤 柯文哲：殘障求職不易',\n",
    "       '人事處議處洪智坤　柯P：不清楚議處結果',\n",
    "       '台北市市政顧問洪智坤，從選前就受到柯文哲信任重用，重金請來當市政顧問之後，在市政府的角色相當吃重，每天七點半的軍機處晨會不能沒有他，現在因為洩公文案，行動不便的洪智坤還坐著輪椅到議會備詢，人事處還要議處他']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['七點', '不便', '不易', '不能', '人事處', '今處理', '信任', '備詢', '公文', '受到', '台北市', '因為', '市政', '市政府', '柯文哲', '案還', '椅到', '殘障', '每天', '求職', '沒有', '洩漏', '洪智坤', '清楚', '現在', '相當', '結果', '著輪', '處晨會', '行動', '角色', '請來當', '議會', '議處', '軍機', '選前', '還坐', '還要', '重用', '重金', '顧問']\n",
      "[[0 0 0 0 0 1 0 0 2 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 2 0 0 0\n",
      "  0 0 0 0]\n",
      " [1 1 0 1 1 0 1 1 1 1 1 1 2 1 1 0 1 0 1 0 1 0 2 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 2]]\n"
     ]
    }
   ],
   "source": [
    "stopwords = ['更新', '看到']\n",
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "for title in ary:\n",
    "    #corpus.append(' '.join(jieba.cut(title)) )\n",
    "    corpus.append(' '.join(\\\n",
    "        [synonym_dic.get(w, w) for w in jieba.cut(title) \\\n",
    "         if synonym_dic.get(w, w) not in stopwords]) )\n",
    "    \n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  3.16227766,  3.74165739,  6.40312424],\n",
       "       [ 3.16227766,  0.        ,  3.16227766,  6.40312424],\n",
       "       [ 3.74165739,  3.16227766,  0.        ,  6.244998  ],\n",
       "       [ 6.40312424,  6.40312424,  6.244998  ,  0.        ]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "euclidean_distances(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "a = np.array([1,1,1,0,0,1])\n",
    "b = np.array([1,1,0,0,1,1])\n",
    "math.sqrt(sum((a - b) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算Cosine相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cs = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立新聞推薦引擎 (根據內容相似度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "news = pandas.read_excel('https://raw.githubusercontent.com/ywchiu/pytextmining/master/data/news.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>政治</td>\n",
       "      <td>新增：立委說法民進黨立法院黨團預計在明天的院會中，讓改制農田水利會的《農田水利會組織通則》修...</td>\n",
       "      <td>https://tw.news.appledaily.com/politics/realti...</td>\n",
       "      <td>【更新】水利會改官派明闖關　綠委24小時前顧議場大門防藍突襲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>論壇</td>\n",
       "      <td>邱俊棠／台中市民、見習醫師；曾任台灣醫學生聯合會對外副會長對於公民參與公眾事務而能得到單位首...</td>\n",
       "      <td>https://tw.news.appledaily.com/forum/realtime/...</td>\n",
       "      <td>請中市府為所當為 加速中火燃煤限制</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>社會</td>\n",
       "      <td>被控來台涉發展情報組織的中國學生周泓旭，因接觸我方外交部官員而露餡落網，今年9月被台北地院一...</td>\n",
       "      <td>https://tw.news.appledaily.com/local/realtime/...</td>\n",
       "      <td>陸生共諜嗆台司法　「不敢公開審理我」</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                            content  \\\n",
       "0       政治  新增：立委說法民進黨立法院黨團預計在明天的院會中，讓改制農田水利會的《農田水利會組織通則》修...   \n",
       "1       論壇  邱俊棠／台中市民、見習醫師；曾任台灣醫學生聯合會對外副會長對於公民參與公眾事務而能得到單位首...   \n",
       "2       社會  被控來台涉發展情報組織的中國學生周泓旭，因接觸我方外交部官員而露餡落網，今年9月被台北地院一...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://tw.news.appledaily.com/politics/realti...   \n",
       "1  https://tw.news.appledaily.com/forum/realtime/...   \n",
       "2  https://tw.news.appledaily.com/local/realtime/...   \n",
       "\n",
       "                            title  \n",
       "0  【更新】水利會改官派明闖關　綠委24小時前顧議場大門防藍突襲  \n",
       "1               請中市府為所當為 加速中火燃煤限制  \n",
       "2              陸生共諜嗆台司法　「不敢公開審理我」  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "titles = []\n",
    "for article in news.iterrows():\n",
    "    corpus.append(' '.join(jieba.cut(article[1]['content'])))\n",
    "    titles.append(article[1]['title'])\n",
    "    #print(article[1]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<899x38318 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 128039 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cs = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(899, 899)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.03170452,  0.05228104, ...,  0.09728591,\n",
       "         0.05344909,  0.02901404],\n",
       "       [ 0.03170452,  1.        ,  0.02798884, ...,  0.0178714 ,\n",
       "         0.01213934,  0.03986744],\n",
       "       [ 0.05228104,  0.02798884,  1.        , ...,  0.02526008,\n",
       "         0.01787311,  0.09818575],\n",
       "       ..., \n",
       "       [ 0.09728591,  0.0178714 ,  0.02526008, ...,  1.        ,\n",
       "         0.11503612,  0.05233539],\n",
       "       [ 0.05344909,  0.01213934,  0.01787311, ...,  0.11503612,\n",
       "         1.        ,  0.0666551 ],\n",
       "       [ 0.02901404,  0.03986744,  0.09818575, ...,  0.05233539,\n",
       "         0.0666551 ,  1.        ]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'喬妹升格宋太太首上工\\u3000現身中國見習近平'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 1, 5, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## argsort\n",
    "a = np.array([2,7,4,8,9,5])\n",
    "a.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "素顏依舊完美　喬妹升格人妻赴中開工 0.321620924623\n"
     ]
    }
   ],
   "source": [
    "for pos in cs[6].argsort()[::-1][1:10]:\n",
    "    if cs[6][pos] >= 0.2:\n",
    "        print(titles[pos],cs[6][pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSimiliarArticle(articleid):\n",
    "    print('查詢文章:', titles[articleid])\n",
    "    for pos in cs[articleid].argsort()[::-1][1:]:\n",
    "        if cs[articleid][pos] >= 0.2:\n",
    "            print('相關文章: ',titles[pos],cs[articleid][pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查詢文章: 【不斷更新】桃園工廠惡火撲滅 6人仍失聯宿舍內發現一堆白骨\n",
      "相關文章:  桃園工廠火勢熄滅　員工宿舍內發現一堆白骨 0.632687215876\n",
      "相關文章:  汽車用品大廠「矽卡」燒毀　資本額達2億 0.581038858053\n",
      "相關文章:  桃園工廠大火6員工失聯　家屬焦急等待 0.440186582123\n",
      "相關文章:  ​台南中古車行大火毀7車　2人嗆傷送醫 0.209014831174\n",
      "相關文章:  【有片】北市東區餐廳竄火　警消急疏散242民眾 0.206064372692\n"
     ]
    }
   ],
   "source": [
    "getSimiliarArticle(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查詢文章: 小嫻婚變冒毒菇　勾于美人「奉茶」夢魘\n",
      "相關文章:  小嫻何守正想離婚　必須先做這件事！ 0.349280045068\n",
      "相關文章:  遭粉絲頁冒名捲「正嫻」口水戰　于美人：跟我真的無關！ 0.328250798371\n",
      "相關文章:  【獨家內幕】太傷！小嫻被分手　何守正當小三面前攤牌 0.267334523553\n",
      "相關文章:  小嫻別傻傻被欺負！女律師說「姐寶」就要這樣對付 0.263939564759\n",
      "相關文章:  【內幕動畫】小嫻婚變何守正姊反擊　不滿媽煮飯侍奉星媳婦 0.243087539052\n",
      "相關文章:  【小嫻離婚】何守正稱沒有遺憾　人妻女星超火「一嘴屁話」 0.234637342071\n",
      "相關文章:  「小嫻不快樂！」　許聖梅：何守正虧欠她 0.233521174702\n",
      "相關文章:  小嫻守正結婚在台沒登記　想離婚只有兩條路 0.228889877093\n",
      "相關文章:  小心！在美結婚台灣沒登記　偷腥照樣能捉姦 0.22759288399\n",
      "相關文章:  【動畫解盤】毒菇跳火線譙seafood　小嫻難瘦香菇 0.21881298349\n",
      "相關文章:  小嫻離婚導火線　拉何守正信妙禪 0.21246482303\n",
      "相關文章:  大姑出面護弟！轟小嫻不能生「媽媽是全台最沒有尊嚴的婆婆」 0.206831525742\n",
      "相關文章:  小嫻信奉妙禪　關鍵原因與何守正有關！ 0.206663657792\n"
     ]
    }
   ],
   "source": [
    "getSimiliarArticle(16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
